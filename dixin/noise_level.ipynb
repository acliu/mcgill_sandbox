{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook estimates the noise level using auto-correlation visibilities and compare it with the posterior probability of the empirical standard deviation of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from hera_cal.io import HERAData, HERACal\n",
    "from scipy.optimize import curve_fit\n",
    "import hera_pspec as hp\n",
    "from pyuvdata import UVData\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the PDF of the complex double Gaussian (CNN) distribution, \n",
    "# which describes the real part of the power of the noise.\n",
    "def real_pdf(z, s):\n",
    "    a = 1/(s)\n",
    "    b = (-np.abs(2*z))/(s)\n",
    "    return a*np.exp(b)\n",
    "\n",
    "# Compute logarithm of the posterior probability function\n",
    "def log_prob(data, sigma, min_sig, max_sig):  \n",
    "    \n",
    "    # log of the prior prob of sigmas[i] -- assuming the prior is a Gaussian distribution\n",
    "    sigmas = np.linspace(min_sig, max_sig, 1000)\n",
    "    log_prior = norm.logpdf(sigmas, loc=sigma, scale=1)\n",
    "    \n",
    "    log_posterior = []\n",
    "    for i in range(len(sigmas)):\n",
    "        log_likelihood = []\n",
    "        for j in range(len(data)):\n",
    "            # compute log of the likelihood\n",
    "            log_likelihood.append(np.log(real_pdf(data[j], sigmas[i])))\n",
    "        log_posterior.append(np.sum(log_likelihood) + log_prior[i])     \n",
    "    \n",
    "    # return the posterior probability for each parameter sigma   \n",
    "    return [sigmas, np.asarray(log_posterior)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load beam model\n",
    "beamfile = 'HERA_NF_dipole_power.beamfits'\n",
    "cosmo = hp.conversions.Cosmo_Conversions()\n",
    "uvb = hp.pspecbeam.PSpecBeamUV(beamfile, cosmo=cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into UVData objects\n",
    "dfile = 'zen.2458101.clean-002.uvh5'\n",
    "uvd = UVData()\n",
    "uvd.read(dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find conversion factor from Jy to mK\n",
    "Jy_to_mK = uvb.Jy_to_mK(np.unique(uvd.freq_array), pol='XX')\n",
    "uvd.data_array *= Jy_to_mK[None, None, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spw_range = [520, 690]\n",
    "\n",
    "# get time between integration [s]\n",
    "t = uvd.integration_time[0]\n",
    "\n",
    "# get channel width [Hz]\n",
    "b = ((uvd.freq_array[0][spw_range[1]] - uvd.freq_array[0][spw_range[0]]))/(spw_range[1]-spw_range[0])\n",
    "# or b = uvd.freq_array[0][1]-uvd.freq_array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get auto-correlation visibilities\n",
    "v1 = uvd.get_data([83,83,'xx'])\n",
    "v2 = uvd.get_data([84,84,'xx'])\n",
    "\n",
    "# averaging by time\n",
    "avg_v1 = np.mean(v1, axis=0)\n",
    "avg_v2 = np.mean(v2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the noise level in frequency space using auto-visibilities\n",
    "s_n = (avg_v1*avg_v2)/(b*t)\n",
    "# get s_n in delay space (Parseval's theorem)\n",
    "s_fftn = len(avg_v1) * s_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the derivation of the $\\mathcal{CNN}$ distribution, we have assumed the standard deviation of the power (noise) is the product of the standard deviation values of visibilities. Let $\\sigma_p$ be the std of the power, then $\\sigma_p = \\sqrt{\\left(\\frac{\\sigma^2_{\\tilde{n}}}{B_{full}}\\right)^2}$, where $B_full$ is fullband width and $\\sigma^2_{\\tilde{n}}$ is the variance of noise in delay space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divided by fullband width to get the noise level in pspec\n",
    "s_p = np.sqrt((s_fftn / (uvd.freq_array[0][1] - uvd.freq_array[0][0]))**2)\n",
    "\n",
    "# get the maximum and minimum values in s_n\n",
    "max_s = max(s_p.real)\n",
    "min_s = min(s_p.real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create uvd object from data between time[16] and time[45]\n",
    "uvd1 = uvd.select(times=np.unique(uvd.time_array)[16:45], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate auto-baseline power spectrum *without normalization*\n",
    "ds = hp.PSpecData(dsets=[uvd1, uvd1], wgts=[None, None], beam=None)\n",
    "ds.rephase_to_dset(0)\n",
    "ds.dsets[0].vis_units = 'mK'\n",
    "ds.dsets[1].vis_units = 'mK'\n",
    "baselines = [(83, 84)]\n",
    "uvp = ds.pspec(baselines, baselines, (0, 1), [('xx', 'xx')], spw_ranges=[(520, 690)], \n",
    "               input_data_weight='identity', norm='I',\n",
    "               taper='none', verbose=True)\n",
    "\n",
    "spw = 0\n",
    "dlys = uvp.get_dlys(spw) * 1e9\n",
    "blp = ((83, 84), (83, 84))\n",
    "key = (spw, blp, 'xx')\n",
    "power = np.real(uvp.get_data(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select power at high delays and average the power by time\n",
    "data = np.mean(power[:,110:150],axis=0)\n",
    "\n",
    "# fit CNN to time-average high-delay power to get an empirical std\n",
    "y, x = np.histogram(data, bins='auto', density=True)\n",
    "x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "sig = curve_fit(real_pdf, x, y, p0=np.std(data))[0]\n",
    "\n",
    "# compute the log of the posterior prob function of the empirical std\n",
    "log_p = log_prob(data, sig, sig-50, sig+50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot sigma_n and sigma_p\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([max_s, max_s], [min(log_p[1]), max(log_p[1])], label='max $\\sigma_{auto}$=%.2f'% max_s)\n",
    "plt.plot([min_s, min_s], [min(log_p[1]), max(log_p[1])], label='min $\\sigma_{auto}$=%.2f'% min_s)\n",
    "plt.plot(log_p[0], log_p[1], label='$\\sigma_{pspec}$=%.2f'% tuple(sig))\n",
    "plt.xlabel(\"$\\sigma$\", fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.ylabel(\"$\\ln(Pr(\\sigma|P))$\", fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
